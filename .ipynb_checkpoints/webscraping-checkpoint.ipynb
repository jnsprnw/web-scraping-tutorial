{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "To understand how web scraping works, you need to understand the basic idea of HTML.\n",
    "\n",
    "HTML uses tags to wrap elements into each other. For example, the following code defines the text `This is a headline` as a (first order) headline:\n",
    "```html\n",
    "<h1>This is a headline</h1>\n",
    "```\n",
    "\n",
    "Everything between the starting `<tag>` tag and the ending `</tag>` is defined by this tag. Other examples are:\n",
    "```html\n",
    "<a>This is a link</a>\n",
    "```\n",
    "The `a`-tag defines a link. Everything between the tags is hence clickable.\n",
    "\n",
    "```html\n",
    "<div>This is a headline</div>\n",
    "```\n",
    "This defines a `div`. This a very common tag. It is used for various purposes and defines a section without intrinsic functionality.\n",
    "\n",
    "Now, you might ask how the browser knows where the link from the first example should point to. We use *attributes* to declare this information:\n",
    "```html\n",
    "<a href=\"http://wikipedia.org\">This is a link</a>\n",
    "```\n",
    "`href` is the the attribute and everything inside the quotes is the value. There are various attributes:\n",
    "```html\n",
    "<span id=\"logo\">Wikipedia</span>\n",
    "<header class=\"introduction\"><p>Long time ago…</p></header>\n",
    "```\n",
    "The first example is a simple text string with the id `logo`. Note ids are unique on websites and hence should only be used once, i.e. there is no second element with the id `logo`.\n",
    "The second example defines a are similarly to `div` but with a semantic meaning that defines it as a »header« of something. Classes can occur multiple times on the website. Inside the header is a `p` tag that defines the text as a paragraph.\n",
    "\n",
    "Some tags don’t follow the opening and closing syntax. Images, for example, are closed in itself (with the trailing `/`):\n",
    "```html\n",
    "<img src=\"https://en.m.wikipedia.org/static/images/mobile/copyright/wikipedia-wordmark-en.svg\" class=\"logo small\" />\n",
    "```\n",
    "Here, the `src` defines the source of the image, i.e. the path to the image. Note how the `class` attribute can define multiple classes to the image.\n",
    "\n",
    "You might worry, how you can memorise all these tags. The good news is, there are not too many. The following tags will probably define 90% of all the content on websites:\n",
    "```html\n",
    "<html>This is wrapped around the whole document</html>\n",
    "<head>This defines the head of the website. It does not contain any visible content, but instead defines, for example, the title of the website.</head>\n",
    "<body>This is wrapped around the content of the website.</body>\n",
    "<div>This is undefined area</div>\n",
    "<section>This is undefined section</section>\n",
    "<main>This is the main part of the website (whatever this is on the website)</main>\n",
    "<header>This is the header of the specific area</header>\n",
    "<footer>This is the footer of the specific area</footer>\n",
    "<aside>This is some additional content of the specific area</aside>\n",
    "<nav>This is the navigation of the website</nav>\n",
    "<h1>This is a first degree headline</h1>\n",
    "<h6>This is a six degree headline</h6>\n",
    "<span>This is a simple text</span>\n",
    "<p>This is a paragraph of text</p>\n",
    "<a>This is a link</a>\n",
    "<ul>\n",
    "    <li>This is a list with two items</li>\n",
    "    <li>This is the second item</li>\n",
    "</ul>\n",
    "<img>\n",
    "```\n",
    "\n",
    "**Please note, HTML only defines areas. It does not style the items (though there are some default styles applied by the browser). The website looks the same no matter if you have something wrapped inside a `header` or a `span` tag. Links will work regardless if they are placed inside the `nav` tags or `h3` tags. The Styling is applied  separately by CSS. HTML is only used to apply semantic meaning to elements. In theory, you could wrap nearly everything inside `div` tags, but the semantic meaning of elements helps for example search engines, screen readers, bots and browsers to make sense of the website. There are some rules of what you should not do (for example wrap a headline inside a paragraph), but browsers will still display the website.**\n",
    "\n",
    "Now, go to any website, right-click and click on *Inspect element* (or something similar depending on your browser). You will see many elements inside each other.\n",
    "\n",
    "Now that you know how websites are built, you can tell a scraper how to extract content from them. When scraping a website, you basically tell a script (or bot, crawler, …) to visit the website, get all its content and navigate through the containing elements.\n",
    "\n",
    "We use the Python library *BeautifulSoup* to »navigate« the HTML. First, import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s give the library some HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup('<h1 id=\"headline\">This is how it all starts</h1><h2 class=\"caption\">A small introduction into something</h2>', 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s say we want the script to find the caption: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"caption\">A small introduction into something</h2>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want the containing text, use `.text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A small introduction into something'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want the value of the `class` attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caption']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2')['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let’s get some real content from a existing website. For that, we use the `request` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get('https://datavis.berlin')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s search for a tag that has the `id` with the value `professional`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 id=\"professional\">\n",
      " <i aria-hidden=\"true\" class=\"icon icon-link\">\n",
      " </i>\n",
      " Professional data visualisation\n",
      "</h2>\n"
     ]
    }
   ],
   "source": [
    "result = soup.find(id='professional')\n",
    "print(result.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonder, what `.prettify()` does? Just remove it and see the result.\n",
    "\n",
    "But what happens if you search by tag and multiple elements have the same tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional data visualisation\n",
      "Places\n",
      "Meet other data people\n",
      "Related degree programmes in Germany\n"
     ]
    }
   ],
   "source": [
    "headlines = soup.find_all('h2')\n",
    "for headline in headlines:\n",
    "    print(headline.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we »loop over« all elements from `headlines` and print out the text for each.\n",
    "\n",
    "Similarly, we can search by class and tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional data visualisation\n",
      "professional\n",
      "Places\n",
      "places\n",
      "Meet other data people\n",
      "meet\n",
      "Related degree programmes in Germany\n",
      "programmes\n"
     ]
    }
   ],
   "source": [
    "headlines = soup.find_all('a', class_='headline')\n",
    "for headline in headlines:\n",
    "    print(headline.get_text())\n",
    "    print(headline.h2['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code reads: Find all elements with the tag `a` that have the class `headline`. Since class is used by Python as command BeautifulSoup used `class_`.\n",
    "\n",
    "Inside each headline link, we search for a `h2` element and print out its `id`.\n",
    "\n",
    "Elements can have any tags. One that helps screen readers is `aria-labelledby`. If we want to search by it we use a slightly different syntax.\n",
    "\n",
    "Inside each headline we search for a link. Save the result in a variable, get the text of the link and also its `href`. If the `href` starts with `https://twitter.com` we print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alsino Skowronnek https://twitter.com/Alsinosko\n",
      "André Pätzold https://twitter.com/alterpaetz\n",
      "Angelo Zehr https://twitter.com/angelozehr\n",
      "Arran Ridley https://twitter.com/arranarranarran\n",
      "Bernd Riedel https://twitter.com/berndriedellery\n",
      "Boris Müller https://twitter.com/borism\n",
      "Burak Korkmaz https://twitter.com/BKorkmaz_KD\n",
      "Cedric Kiefer https://twitter.com/CedricKiefer\n",
      "Christian Laesser https://twitter.com/christianlaessr\n",
      "Christian Schlippes https://twitter.com/geplapper\n",
      "Christopher Möller https://twitter.com/chrtze\n",
      "Christopher Pietsch https://twitter.com/chrispiecom\n",
      "David Elsche https://twitter.com/ElscheDavid\n",
      "David Wendler https://twitter.com/newreld\n",
      "Dilyana Suleymanova https://twitter.com/DilyanaFlower\n",
      "Dirk Aschoff https://twitter.com/dirkaschoff\n",
      "Dirk Brockmann https://twitter.com/DirkBrockmann\n",
      "Elena Erdmann https://twitter.com/elena_erdmann\n",
      "Fabian Dinklage https://twitter.com/fdnklg\n",
      "Fabian Ehmel https://twitter.com/fabianehmel\n",
      "Fidel Thomet https://twitter.com/fidelthomet\n",
      "Flavio Gortana https://twitter.com/flaviogortana\n",
      "Francesca Morini https://twitter.com/fr_morini\n",
      "Gregor Aisch https://twitter.com/driven_by_data\n",
      "Hans Hack https://twitter.com/hnshck\n",
      "Heike Otten https://twitter.com/HeikeOtten_\n",
      "Hendrik Lehmann https://twitter.com/plateauton\n",
      "Jack Schaedler https://twitter.com/JackSchaedler\n",
      "Jan-Erik Stange https://twitter.com/HerrStange\n",
      "Jonas Parnow https://twitter.com/zeto\n",
      "Julian Stahnke https://twitter.com/julians\n",
      "Julius Tröger https://twitter.com/juliustroeger\n",
      "Katrin Glinka https://twitter.com/kaglinka\n",
      "Kim Albrecht https://twitter.com/kimay\n",
      "Lars Grammel https://twitter.com/lgrammel\n",
      "Lennart Hildebrandt https://twitter.com/len_hil\n",
      "Letty https://twitter.com/Lettebowskie\n",
      "Lina Wassong https://twitter.com/wassonglina\n",
      "Lisa Charlotte Rost https://twitter.com/lisacrost\n",
      "Lisa Rienermann https://twitter.com/lisarienermann\n",
      "Marian Dörk https://twitter.com/nrchtct\n",
      "Marie-Louise Timcke https://twitter.com/datentaeterin\n",
      "Mark-Jan Bludau https://twitter.com/markiaaan\n",
      "Maximilian Nertinger https://twitter.com/studio_inca\n",
      "Michael Hoerz https://twitter.com/data_meining\n",
      "Michael Kreil https://twitter.com/michaelkreil\n",
      "Mila Frerichs https://twitter.com/milafrerichs\n",
      "Moritz Klack https://twitter.com/moklick\n",
      "Nicolas Kayser-Bril https://twitter.com/nicolaskb\n",
      "Paul Blickle https://twitter.com/colorfuldata\n",
      "Paul Heinicker https://twitter.com/paulpunkt\n",
      "Pauline Gallinat https://twitter.com/paulinegallinat\n",
      "Pierre La Baume https://twitter.com/labaume_de\n",
      "René Rieger https://twitter.com/rene_rieger\n",
      "Sandra Rendgen https://twitter.com/srendgen\n",
      "Sara Akhlaq https://twitter.com/alltheakhlaq/\n",
      "Sascha Venohr https://twitter.com/venohr\n",
      "Sebastian Meier https://twitter.com/seb_meier\n",
      "Sebastian Sadowski https://twitter.com/sadowskiseb\n",
      "Sebastian Vollnhals https://twitter.com/yetzt\n",
      "Stefan Wehrmeyer https://twitter.com/stefanwehrmeyer\n",
      "Stephan Thiel https://twitter.com/stphnthiel\n",
      "Tobias Kauer https://twitter.com/tobi_vierzwo\n",
      "Tori Boeck https://twitter.com/toridykes\n"
     ]
    }
   ],
   "source": [
    "headlines = soup.find('ul', attrs={'aria-labelledby' : 'people'})\n",
    "for headline in headlines:\n",
    "    link = headline.find('a')\n",
    "    text = link.get_text()\n",
    "    href = link['href']\n",
    "    if (href.startswith('https://twitter.com')):\n",
    "        print(text, href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s safe it to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('people.csv', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "\n",
    "    headlines = soup.find('ul', attrs={'aria-labelledby' : 'people'})\n",
    "    for headline in headlines:\n",
    "        link = headline.find('a')\n",
    "        text = link.get_text()\n",
    "        href = link['href']\n",
    "        if (href.startswith('https://twitter.com')):\n",
    "            writer.writerow([text,href]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
